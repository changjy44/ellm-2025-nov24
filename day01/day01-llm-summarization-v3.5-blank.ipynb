{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1 - Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 Models\n",
    "\n",
    "The <code>flan-t5</code> is a Text-To-Text Transfer Transformer (T5) that is capable of performing zero-shot NLP task such as summary, simple reasoninig, answering questions, etc. \n",
    "\n",
    "Some T5 models from Huggingface\n",
    "- [<code>google/flan-t5-base</code>](https://huggingface.co/google/flan-t5-base)\n",
    "- [<code>google/flan-t5-small</code>](https://huggingface.co/google/flan-t5-small)\n",
    "- [<code>google/flan-t5-xl</code>](https://huggingface.co/google/flan-t5-xl)\n",
    "- [<code>google/flan-t5-xxl</code>](https://huggingface.co/google/flan-t5-xxl) - full model\n",
    "\n",
    "Complete list of [T5 models](https://huggingface.co/models?search=google/flan) on Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/flan-t5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load tokenizer and model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "When a traveler in north central Massachusetts takes the wrong fork\n",
    "at the junction of the Aylesbury pike just beyond Dean's Corners he\n",
    "comes upon a lonely and curious country. The ground gets higher, and\n",
    "the brier-bordered stone walls press closer and closer against the ruts\n",
    "of the dusty, curving road. The trees of the frequent forest belts\n",
    "seem too large, and the wild weeds, brambles, and grasses attain a\n",
    "luxuriance not often found in settled regions. At the same time the\n",
    "planted fields appear singularly few and barren; while the sparsely\n",
    "scattered houses wear a surprizing uniform aspect of age, squalor, and\n",
    "dilapidation. Without knowing why, one hesitates to ask directions\n",
    "from the gnarled, solitary figures spied now and then on crumbling\n",
    "doorsteps or in the sloping, rock-strewn meadows. Those figures are\n",
    "so silent and furtive that one feels somehow confronted by forbidden\n",
    "things, with which it would be better to have nothing to do. When a\n",
    "rise in the road brings the mountains in view above the deep woods,\n",
    "the feeling of strange uneasiness is increased. The summits are too\n",
    "rounded and symmetrical to give a sense of comfort and naturalness, and\n",
    "sometimes the sky silhouettes with especial clearness the queer circles\n",
    "of tall stone pillars with which most of them are crowned.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"Mr. Dursley was the director of a ﬁrm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no ﬁner boy anywhere.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn’t want Dudley mixing with a child like that.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Templates\n",
    "The following Github repository contains a list of prompt templates that you can use with T5.\n",
    "\n",
    "[https://github.com/google-research/FLAN/blob/main/flan/templates.py](https://github.com/google-research/FLAN/blob/main/flan/templates.py)\n",
    "\n",
    "Look through them and select a summarization template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short summary for this text: The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn’t want Dudley mixing with a child like that.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a prompt\n",
    "prompt = f\"Write a short summary for this text: {text}\"\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 8733,     3,     9,   710,  9251,    21,    48,  1499,    10,    37,\n",
      "          8633,  8887,     7,   141,   762,    79,  1114,     6,    68,    79,\n",
      "            92,   141,     3,     9,  2829,     6,    11,    70,  4016,  2971,\n",
      "            47,    24, 10843,   133,  2928,    34,     5,   328,   737,    22,\n",
      "            17,   317,    79,   228,  4595,    34,     3,    99,  1321,   435,\n",
      "            91,    81,     8, 16023,     7,     5,  8667,     5, 16023,    47,\n",
      "          8667,     5,  8633,  8887,    22,     7,  4806,     6,    68,    79,\n",
      "         12381,    22,    17,  1736,    21,   633,   203,   117,    16,   685,\n",
      "             6,  8667,     5,  8633,  8887,   554, 15443,   255,   737,    22,\n",
      "            17,    43,     3,     9,  4806,     6,   250,   160,  4806,    11,\n",
      "           160,   207,    18,  1161,    18,    29,    32,  8052,  2553,   130,\n",
      "            38,    73,   308,   450,  8887,  1273,    38,    34,    47,   487,\n",
      "            12,    36,     5,    37,  8633,  8887,     7,  6660, 28002,    15,\n",
      "            26,    12,   317,   125,     8, 11195,   133,   497,     3,    99,\n",
      "             8, 16023,     7,  4363,    16,     8,  2815,     5,    37,  8633,\n",
      "          8887,     7,  2124,    24,     8, 16023,     7,   141,     3,     9,\n",
      "           422,   520,     6,   396,     6,    68,    79,   141,   470,   237,\n",
      "           894,   376,     5,   100,  4940,    47,   430,   207,  1053,    21,\n",
      "          2627,     8, 16023,     7,   550,   117,    79,   737,    22,    17,\n",
      "           241,   970,    26,  1306, 10623,    28,     3,     9,   861,   114,\n",
      "            24,     5,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# TODO: tokenize the text\n",
    "enc_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "print(enc_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short summary for this text: The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn’t want Dudley mixing with a child like that.</s>\n"
     ]
    }
   ],
   "source": [
    "# TODO: Decode the token\n",
    "print(tokenizer.decode(enc_prompt.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate summary with model \n",
    "enc_summary = model.generate(enc_prompt.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,    37,   684,    19,     3,     9,     3,     7, 28426,    11,\n",
      "            73, 20905,   286,     5,     1]])\n"
     ]
    }
   ],
   "source": [
    "print(enc_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,    37,  8633,  8887,     7,   141,     3,     9,  2829,     6,\n",
      "            11,    70,  4016,  2971,    47,    24, 10843,   133,  2928,    34,\n",
      "             5]])\n",
      "The Dursleys had a secret, and their greatest fear was that somebody would discover it.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Decode the summary\n",
    "print(enc_summary)\n",
    "summary = tokenizer.decode(enc_summary[0], skip_special_tokens=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "- Set the temperate \n",
    "- Top P\n",
    "- Top K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> The Dursleys had a secret, and their greatest fear was that somebody would discover it.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Configure the LLM\n",
    "config = GenerationConfig(\n",
    "   do_sample=True,\n",
    "   temperature = 4.1,\n",
    "   max_new_token=100,\n",
    "   min_new_token=100\n",
    ")\n",
    "\n",
    "enc_summary = model.generate(enc_prompt.input_ids, generation_config=config)\n",
    "summary = tokenizer.decode(enc_summary[0])\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ellm-2025-nov24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
